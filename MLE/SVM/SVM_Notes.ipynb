{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd6b3d58-1f8e-444c-bef5-48c5d88b8143",
   "metadata": {},
   "source": [
    "#  Support Vector Machine (SVM) - Introduction\n",
    "\n",
    "## ğŸ”¹ What is SVM?\n",
    "**Support Vector Machine (SVM)** is a **supervised machine learning algorithm** used for **classification** and **regression** tasks.  \n",
    "It is most commonly used for **binary classification** (e.g., yes/no, spam/ham).\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¡ Basic Idea\n",
    "SVM finds the **best boundary (hyperplane)** that separates data points of different classes.  \n",
    "It tries to **maximize the margin** â€” the distance between the hyperplane and the nearest data points from each class.\n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ How It Works\n",
    "1. Plot data points in space (2D or 3D).\n",
    "2. Draw possible lines (or planes) that separate the classes.\n",
    "3. Choose the **line/plane with the maximum margin**.\n",
    "4. For non-linear data, use a **kernel trick** to project data into a higher dimension where it becomes separable.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§© Key Terms\n",
    "| Term | Description |\n",
    "|------|--------------|\n",
    "| **Hyperplane** | The decision boundary separating classes. |\n",
    "| **Support Vectors** | Data points closest to the hyperplane; they define the margin. |\n",
    "| **Margin** | The distance between the hyperplane and the support vectors. |\n",
    "| **Kernel Trick** | A mathematical method to handle non-linear data by transforming it into higher dimensions. |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§® Types of SVM\n",
    "- **Linear SVM** â†’ Straight-line decision boundary  \n",
    "- **Non-linear SVM** â†’ Uses kernel functions (Polynomial, RBF, Sigmoid) to handle complex data\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¼ Applications\n",
    "- Text & spam classification  \n",
    "- Face and object recognition  \n",
    "- Medical diagnosis (e.g., tumor classification)  \n",
    "- Fraud detection in finance  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410d676f-b825-4cbe-a613-9aaa91afce4c",
   "metadata": {},
   "source": [
    "#  Support Vector Machine (SVM) â€“ Key Terminologies\n",
    "\n",
    "## 1. **Hyperplane**\n",
    "- The **decision boundary** that separates data points of different classes.  \n",
    "- In **2D**, itâ€™s a **line**; in **3D**, itâ€™s a **plane**; in higher dimensions, itâ€™s a **hyperplane**.  \n",
    "- SVM tries to find the **best hyperplane** that divides the classes with the **maximum margin**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab7e1d7-9264-46ac-942b-474ed110b95d",
   "metadata": {},
   "source": [
    "![hyperplane](./hyperplane.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a097a2-1f2d-46aa-856d-4079f81e1d12",
   "metadata": {},
   "source": [
    "## 2. **Support Vectors**\n",
    "- The **data points that are closest to the hyperplane**.  \n",
    "- These points directly influence the **position and orientation** of the hyperplane.  \n",
    "- If any of these points are moved or removed, the hyperplane will change.  \n",
    "- Hence, they are called **â€œsupportâ€** vectors â€” they support the boundary.\n",
    "![support_vect](./supportvectors.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861639df-a7a8-4ee0-b925-b690f436a7cc",
   "metadata": {},
   "source": [
    "## 3. **Margin**\n",
    "- The **distance between the hyperplane and the nearest support vectors** from each class.  \n",
    "- SVM aims to **maximize this margin** for better separation and generalization.  \n",
    "- Larger margin â†’ better model performance and stability.\n",
    "![margin](./margin.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cef99b-074b-4df4-b6d7-8e0d4e10f690",
   "metadata": {},
   "source": [
    "## 4. **Kernel Trick**\n",
    "- A **mathematical technique** used to handle **non-linear data**.  \n",
    "- It transforms the input data into a **higher-dimensional space**, where it becomes **linearly separable**.  \n",
    "- Common kernel types:\n",
    "  - **Linear Kernel** â†’ Straight-line separation  \n",
    "  - **Polynomial Kernel** â†’ Curved separation  \n",
    "  - **RBF (Radial Basis Function)** â†’ Circular or complex separation  \n",
    "  - **Sigmoid Kernel** â†’ S-shaped decision boundary\n",
    "  ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dbd8bf-ff9b-49c1-85cb-837d2e58562f",
   "metadata": {},
   "source": [
    "## 5. **Decision Boundary**\n",
    "- The **line or surface** that separates one class from another based on the SVM model.  \n",
    "- Points on one side belong to one class, and those on the other side belong to the second class.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. **Margin Width (Distance Between Support Vectors)**\n",
    "- The **total width** between the two margin boundaries.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc536f1",
   "metadata": {},
   "source": [
    "![nonlinear](./non_linear_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ba03a2",
   "metadata": {},
   "source": [
    "![linear_svm](./Linear_Linear_SVM_(Fails_on_Non-Linear_Data).png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e076f145",
   "metadata": {},
   "source": [
    "![rbf_svm](./RBF_RBF_Kernel_SVM_(Handles_Non-Linear_Data).png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331fbf54",
   "metadata": {},
   "source": [
    "# Hyper Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4623905a",
   "metadata": {},
   "source": [
    "## What are Hyperparameters?\n",
    "\n",
    "ğŸ‘‰ Hyperparameters are **settings or control**s that you choose before training your SVM model.\n",
    "They decide how the model learns and **how flexible or strict** it should be while separating data.\n",
    "\n",
    "Think of them like tuning knobs ğŸ”§ on a machine.\n",
    "\n",
    "\n",
    "### Important SVM Hyperparameters\n",
    "\n",
    "There are 3 main hyperparameters youâ€™ll use often:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5190f04",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "486b405d",
   "metadata": {},
   "source": [
    "| Hyperparameter | Symbol / Name            | Works With               | Simple Meaning                                                  |\n",
    "| -------------- | ------------------------ | ------------------------ | --------------------------------------------------------------- |\n",
    "| 1ï¸âƒ£ `C`        | Regularization parameter | All kernels              | Controls how strictly the model tries to classify training data |\n",
    "| 2ï¸âƒ£ `gamma`    | RBF kernel parameter     | RBF / Polynomial kernels | Controls how far the influence of a single data point goes      |\n",
    "| 3ï¸âƒ£ `kernel`   | Type of boundary         | All                      | Decides the shape of the boundary (line, curve, etc.)           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7e71e8",
   "metadata": {},
   "source": [
    "# SVM Hyperparameters â€” Simple Notes (for students)\n",
    "\n",
    "##  1ï¸âƒ£ `C` â€” The Strictness Controller\n",
    "**Imagine:** Youâ€™re drawing a line to separate red and blue points.\n",
    "\n",
    "- **If `C` is large (e.g. `C = 1000`)** â†’  \n",
    "  The SVM tries *very* hard to correctly classify every training point (even noise).  \n",
    "  ğŸ‘‰ The boundary becomes **wiggly** and can **overfit**.\n",
    "\n",
    "- **If `C` is small (e.g. `C = 0.1`)** â†’  \n",
    "  The SVM allows some mistakes to get a **smoother boundary**.  \n",
    "  ğŸ‘‰ **Better generalization** (less overfitting).\n",
    "\n",
    "**In short:**\n",
    "\n",
    "| C Value      | Effect                                              |\n",
    "|--------------|-----------------------------------------------------|\n",
    "| High (strict)| Perfect training accuracy but may overfit ğŸ˜¬        |\n",
    "| Low (relaxed)| Allows errors but generalizes better ğŸ˜             |\n",
    "\n",
    "---\n",
    "\n",
    "##  2ï¸âƒ£ `gamma` â€” The Influence Radius\n",
    "*(Used mostly with RBF or polynomial kernels.)*\n",
    "\n",
    "**Imagine:** Each data point creates a **â€œbubble of influenceâ€** around it.\n",
    "\n",
    "- **High `gamma` (Î³ large)** â†’  \n",
    "  Each pointâ€™s bubble is **small** â†’ model focuses on **nearby points** â†’ **very complex** boundary.\n",
    "\n",
    "- **Low `gamma` (Î³ small)** â†’  \n",
    "  Each pointâ€™s bubble is **large** â†’ model looks at **broader patterns** â†’ **smoother** boundary.\n",
    "\n",
    "**In short:**\n",
    "\n",
    "| gamma Value | Effect                          |\n",
    "|-------------|----------------------------------|\n",
    "| High        | Very detailed, may overfit       |\n",
    "| Low         | Smoother, may underfit           |\n",
    "\n",
    "---\n",
    "\n",
    "##  3ï¸âƒ£ `kernel` â€” The Shape of the Boundary\n",
    "\n",
    "| Kernel  | Meaning              | Shape of Boundary        | Example Use                          |\n",
    "|---------|----------------------|--------------------------|--------------------------------------|\n",
    "| linear  | Straight line        | Linear                   | Simple, fast when data is linear     |\n",
    "| poly    | Polynomial curve     | Curved                   | When relationship is curved          |\n",
    "| rbf     | Radial Basis Function| Circular / complex       | Most common for non-linear data      |\n",
    "| sigmoid | S-shaped             | Neural-net like          | Rarely used                          |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§© Putting It All Together â€” Example\n",
    "\n",
    "```python\n",
    "from sklearn.svm import SVC\n",
    "model = SVC(C=1, kernel='rbf', gamma=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a6dc31",
   "metadata": {},
   "source": [
    "![c_gamma](./c_gamma.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d7e2c8",
   "metadata": {},
   "source": [
    " ğŸ¯ SVM Hyperparameters: Understanding `C` and `gamma`\n",
    "\n",
    "Below image shows how changing **C** and **gamma** affects the **SVM decision boundary**  \n",
    "for classifying two classes (red ğŸ”´ and blue ğŸ”µ).\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "The image contains **4 subplots**:\n",
    "\n",
    "| Row | Parameter Changed | Description |\n",
    "|------|-------------------|--------------|\n",
    "| **Top Row** | `C` (Regularization Parameter) | Controls **model strictness** â€” how much it punishes errors. |\n",
    "| **Bottom Row** | `gamma` (Kernel Coefficient) | Controls **influence of each point** â€” how far a data point affects the decision boundary. |\n",
    "\n",
    "---\n",
    "\n",
    "##  1ï¸âƒ£ Top Left â€” Low **C**\n",
    "\n",
    "- The separating line is **smooth and simple**.\n",
    "- Some points are misclassified, but the model focuses on the **overall pattern**.\n",
    "- Not strict â€” allows small mistakes for better generalization.\n",
    "\n",
    " **Think like:**  \n",
    "> A teacher who allows small errors so students understand the big picture.\n",
    "\n",
    "âœ… **Good:** Works well for noisy data.  \n",
    "âŒ **Bad:** Might underfit if data is complex.\n",
    "\n",
    "---\n",
    "\n",
    "##  2ï¸âƒ£ Top Right â€” High **C**\n",
    "\n",
    "- The boundary becomes **very curved (wiggly)**.  \n",
    "- The model tries to **classify every point correctly**.  \n",
    "- Very strict â†’ can lead to **overfitting**.\n",
    "\n",
    " **Think like:**  \n",
    "> A teacher who demands perfect answers â€” no mistakes allowed!\n",
    "\n",
    "âœ… **Good:** Works for clear, noise-free data.  \n",
    "âŒ **Bad:** Poor performance on new data.\n",
    "\n",
    "---\n",
    "\n",
    "##  3ï¸âƒ£ Bottom Left â€” Low **gamma**\n",
    "\n",
    "- Each data point has a **large area of influence**.\n",
    "- The decision boundary is **smooth and broad**.\n",
    "- The model looks at the **overall shape** of data.\n",
    "\n",
    " **Think like:**  \n",
    "> Every studentâ€™s result affects the whole class average.\n",
    "\n",
    "âœ… **Good:** Captures general trends.  \n",
    "âŒ **Bad:** May miss small, complex patterns.\n",
    "\n",
    "---\n",
    "\n",
    "##  4ï¸âƒ£ Bottom Right â€” High **gamma**\n",
    "\n",
    "- Each point influences only its **immediate neighbors**.\n",
    "- Boundary becomes **complex and twisty**.\n",
    "- Fits the training data perfectly â€” but **overfits** easily.\n",
    "\n",
    " **Think like:**  \n",
    "> Each studentâ€™s mark affects only their small friend group.\n",
    "\n",
    "âœ… **Good:** Useful when data has fine details.  \n",
    "âŒ **Bad:** Poor generalization to new data.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§® Summary Table\n",
    "\n",
    "| Parameter | Low Value | High Value |\n",
    "|------------|------------|-------------|\n",
    "| **C** | Smooth, allows mistakes, generalizes well | Wiggly, fits all points, may overfit |\n",
    "| **gamma** | Smooth, wide influence, global pattern | Tight, small influence, overfits locally |\n",
    "\n",
    "---\n",
    "\n",
    "##  Simple Analogy\n",
    "\n",
    "Imagine throwing **pebbles into a pond**:\n",
    "\n",
    "- **Low gamma:** Each pebble makes **big waves**, influencing the whole pond (smooth boundary).  \n",
    "- **High gamma:** Each pebble makes **tiny ripples**, influencing only nearby area (wiggly boundary).\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§­ Final Takeaway\n",
    "\n",
    "- Use **low C** and **low gamma** â†’ for **smooth, simple** patterns.  \n",
    "- Use **high C** or **high gamma** â†’ only if data is **complex and detailed**.  \n",
    "- Balance both using **cross-validation** for best performance.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a65f20",
   "metadata": {},
   "source": [
    "#  Cross Validation \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¡ Definition\n",
    "\n",
    "**Cross-validation** is a method used to check how well a machine learning model performs on **new or unseen data**.\n",
    "\n",
    "It helps us find out if our model is:\n",
    "- **Overfitting** (too focused on training data), or  \n",
    "- **Underfitting** (too simple to learn patterns).\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“˜ Simple Example\n",
    "\n",
    "Imagine you have **100 student marks** data, and you want to build a model to **predict student performance**.\n",
    "\n",
    "If you only train and test on the same students â†’ your model might **memorize** instead of **learning**.\n",
    "\n",
    "So, we divide the data into parts and test the model on different groups â€” this is **cross-validation**.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§© How It Works â€” Step by Step (K-Fold Cross Validation)\n",
    "\n",
    "Letâ€™s take **K = 5** folds.\n",
    "\n",
    "| Fold | Training Data | Testing Data |\n",
    "|------|----------------|---------------|\n",
    "| 1 | Parts 2,3,4,5 | Part 1 |\n",
    "| 2 | Parts 1,3,4,5 | Part 2 |\n",
    "| 3 | Parts 1,2,4,5 | Part 3 |\n",
    "| 4 | Parts 1,2,3,5 | Part 4 |\n",
    "| 5 | Parts 1,2,3,4 | Part 5 |\n",
    "\n",
    "So, the model is trained **5 times**, each time using a different test part.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Š Graphical Understanding\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaf3d60",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8495776f",
   "metadata": {},
   "source": [
    "\n",
    "ğŸ§  After all 5 rounds â†’ take the **average accuracy**  \n",
    "â†’ This gives a **more reliable performance score**.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ–¼ï¸ Simple Diagram Explanation\n",
    "\n",
    "Imagine your dataset is split into 5 boxes (folds):\n",
    "\n",
    "| Fold 1 | Fold 2 | Fold 3 | Fold 4 | Fold 5 |\n",
    "|:------:|:------:|:------:|:------:|:------:|\n",
    "| âœ… | âœ… | âœ… | âœ… | ğŸ§ª |\n",
    "| âœ… | âœ… | âœ… | ğŸ§ª | âœ… |\n",
    "| âœ… | âœ… | ğŸ§ª | âœ… | âœ… |\n",
    "| âœ… | ğŸ§ª | âœ… | âœ… | âœ… |\n",
    "| ğŸ§ª | âœ… | âœ… | âœ… | âœ… |\n",
    "\n",
    "âœ… = used for **training**  \n",
    "ğŸ§ª = used for **testing**\n",
    "\n",
    "Each fold gets one turn as the test set.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41d67e9",
   "metadata": {},
   "source": [
    "#  What is GridSearchCV?\n",
    "\n",
    "##  Definition\n",
    "**GridSearchCV** (Grid Search Cross-Validation) is a method used to **find the best hyperparameters** for a machine learning model automatically.\n",
    "\n",
    "It tests **different combinations** of parameters (like `C`, `gamma`, `kernel` in SVM) and tells you which one gives the **best accuracy**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0163a985",
   "metadata": {},
   "source": [
    "##  How It Works\n",
    "\n",
    "1. **You choose parameters to test** (a grid of values).  \n",
    "2. **GridSearchCV** trains and tests your model for every combination using **cross-validation**.  \n",
    "3. It returns:\n",
    "   - Best parameters\n",
    "   - Best model\n",
    "   - Best accuracy score\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fff9adf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
